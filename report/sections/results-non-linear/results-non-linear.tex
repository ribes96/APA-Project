% 6. The results obtained using
%  at least two general non-linear methods (indicating
% the best set of parameters for each one); for both
%  classifcation and regression
% tasks, any of: one-hidden-layer MLP, the RBFNN, the SVM with RBF kernel, a
% Random Forest

\section{Results obtained using non-linear methods}

\subsection{Random Forest}

\red{
\begin{itemize}
    \item Puesto que random forest ya hace algún tipo de resampling, quizá era mejor probarlo con el dataset preprocesado original, y no con los 51 bags que hemos creado. Comentar por qué hemos hecho esto y lo que podría pasar
    \item Comentar los tipos de bosques que han quedado después del crossvalidation: la cantidad de árboles que tiene cada uno, el mínimo de instancias en cada nodo, la cantidad de atributos que se consideran, etc.
    \item Qué puede afectar a este modelo y cómo nos va a afectar a nosotros
    \item Mostrar los resultados y la confussion matrix
    \item Comentar los resultados
    \item Comentar las diferencias entre cada uno de los dos datasets
    \item Comentar por qué creemos que los resultados han sido buenos o malos
\end{itemize}
}

Random forests build decision trees using bagging to get different samples and combinations of variables to train on, and classify given test data by majority vote of all decision trees. This method is said to be quite robust even to imbalanced data, but does not create bags with equal parts of both classes, so we chose to call the random forest method with our preprocessed data. As the already balanced train samples are then divided into bags the models should give a more or less good result in the testing phase. Although it is possible to define the depth of trees and number of variables to choose we did not set these parameters fixed, because after trying different combinations there was none to create results clearly superior to the others.

\subsection{Neural Network}

\red{
\begin{itemize}
    \item Ver en promedio cuantas neuronas había en cada modelo y cuanta regularización se ha usado, después de los datos de crossvalidation
    \item Indicar que no se han hecho skips, y que únicamente hay una capa oculta\ldots
    \item No hace ningún tipo de distinción entre los tipos de datos de entrada. Para él tozdo son reales, los booleanos también
    \item Qué puede afectar a este modelo y cómo nos puede afectar a nosotros
    \item Mostrar los resultados y la confussion matrix
    \item Comentar los resultados
    \item Comentar las diferencias entre cada uno de los dos datasets
    \item Comentar por qué creemos que los resultados han sido buenos o malos
\end{itemize}
}

Neural networks make use of the biological system of neurons nesting functions into each other to classify the given input data. In our case we used a single-hidden-layer neural network. We did not allow skipping becauses a test with the skipping option set did not improve the results. We neither set a regularization parameter because this also let to poorer results when testing new data on the calculated models.