% 4. The resampling protocol (training/test, cross-validation, etc) that you have used (see 3.3)
\section{Resampling protocol}

After the pre-processing we have $2$ datasets with $448$ instances. \textit{thoraric.original} has $23$ attributes and \textit{thoraric.removed} has $19$. $0.85\%$ of the patients have the target variable (DIED) equals FALSE.

The following lines explain the resampling protocol that we have used. All the numbers used can easilly be tuned in the scripts provided.

To test our models we split our data into two different datasets, one for training and one for testing. The testing dataset will contain $\frac{1}{3}$ of all the patients. As they are chosen randomly, it is expected that the proportion of patients in each of the classes is kept. We will only use the testing dataset in the end, to test our models.

In the training dataset we have $299$ patients, and it is expected that over $254$ of them will be DIED $=$ FALSE and $45$ will be DIED $=$ TRUE.
As most of the models are sensitive to non-balanced datasets, we need to do something to balance our training dataset. We use the \textit{bagging} algorithm to generate $51$ balanced datasets, and each one of them will be used to train $51$ models of the same type. That number could be different, but it is good for it to be odd, to avoid ties. Then, to generate a prediction, each of the models will be used to make a \textit{hard} vote, and the class predicted by the majority will be the answer. This way we have constructed what we have called a \textit{super-model} built with simpler models.

Each of the \textit{bags} will contain the same amount of instances. As we want them to be balanced, all of them will contain every TRUE instance in the training dataset, and a random sample of the same size of the FALSE instances. Thus, each bag will have over $2 \times 45 = 90$ instances.
