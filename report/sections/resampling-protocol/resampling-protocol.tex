% 4. The resampling protocol (training/test, cross-validation, etc) that you have used (see 3.3)
\section{Resampling protocol}

After the preprocessing we have two datasets, each of them with $448$ instances. The dataset \textit{thoraric.original} has $23$ attributes and the dataset \textit{thoraric.removed} has $19$ attributes after the eliminations explained in section \ref{sec-elim-var}. For about $85\%$ of the patients the target variable (DIED) equals FALSE.

The following lines explain the resampling protocol that we have used. All the numbers used can easilly be tuned in the scripts provided.

To test our models we split the data into two different datasets, one for training and one for testing. The testing dataset will contain $\frac{1}{3}$ of all the patients. As they are chosen randomly, it is expected that the proportion of patients in each of the classes is kept. We will only use the testing dataset to test our models.

In the training dataset we have $299$ patients, and it is expected that about $254$ of them will have the variable DIED $=$ FALSE and $45$ will have DIED $=$ TRUE.
As most of the models are sensitive to imbalanced datasets, we need to improve the balance of the training dataset. We use the \textit{bagging} algorithm to generate $11$ balanced datasets, each of them will be used to train a model. We chose the number of bags to be odd to avoid ties. We also tried different quantities of bags to the result that the F2 score does not improve any more with a number of bags larger than $11$, so we determined this to be the quantity of bags to use. Then, to generate a prediction, each of the models will be used to make a \textit{hard} vote, and the class predicted by the majority will be the result for an instance. This way we have constructed what we have called a \textit{super-model} consisting of a list of $11$ models that return a final vote for every instance of the testing dataset.

Each of the \textit{bags} will contain the same amount of instances. As we want them to be balanced, all of them will contain every DIED $=$ TRUE instance in the training dataset, and a random sample of the same size of the DIED $=$ FALSE instances. Thus, each bag will have about $2 \times 45 = 90$ instances.
